# 自述文件

## 说明

基于树莓派开发的智能导盲杖
项目创建时间：24/10/25  
团队成员：  
分工：

斯坦福大学同型产品：

- [Github 仓库地址](https://github.com/pslade2/AugmentedCane/blob/main/README.md)
- [斯坦福论文地址](https://www.science.org/doi/10.1126/scirobotics.abg6594)
- [该项目 Github 仓库地址](https://github.com/404-d/smart-cane)
- 使用到的软件：123D Design、Advanced IP Scanner、imager、PuTTY、Bambu Studio、Git、VisualStudio Code

## 简介

该项目开发板为 RaspberryPi 4B，使用 C++和 python 语言编写，外壳等结构件为 ASA 3D 打印

### 功能

#### 标准障碍物 #1

我们使用 tof 镜头和 AI 识别障碍物，识别障碍物后返回其方位，蜂鸣器和转子马达发出提示，提醒用户，同时减速电机带动全向轮向返回方位反方向运动，牵引用户进行避障运动，具体原理请参阅 #3 人物

#### 下沉和突起障碍物 #2

我们将其中一个 tof 镜头放在了拐杖的顶端，可以识别前端物体距离的突然变化：

1. 当遇到下沉障碍物时，tof 镜头返回数据突然增大，即可识别为下沉障碍物，我们有两个选择：
   1. 减速电机左右移动，检测到返回数据变回原来的值，可以知道这是一个坑，引导用户向左或向右避让
   2. 左右移动发现数据没有较大改变，可以识别为这是一个类似马路牙子的障碍，蜂鸣器和转子马达提醒用户，抬起拐杖进行避让
2. 当遇到上升障碍物时，返回数据突然减小，可以识别为上升障碍物
   1. 如果上升后数据改变小，可以知道这是一个坡/台阶/柱子，可以避让或跳过
   2. 如果数据变化较大，说明这是一个台阶，需要提醒用户抬起拐杖并注意障碍物

#### 人物 #3

考虑到视障人群独自的出行范围不包含人流量特别大的地方，人物和标准障碍物的不同之处在于人群会移动，而标准障碍物不会移动，我们使用了 AI 的人物识别算法，将识别到人物时的(记为 $T_1$)位置标记为 $L_1$,使用三角函数和人物($v_p$)、用户移动速度($v_u$)，可以计算出该人物 $T_n$时刻的位置  
使用极坐标系和角度制：

- 拐杖前端加强
- 盲人采访
- 激光雷达

# 开发日志

### 24/10/25

编写 README.md

---

### 24/11/8

整理开发文档

---

### 24/12/5

安装 raspbainOS  
配置 SSH/VNC

---

### 24/12/6

安装 WiringPi `vision=3.10`

---

### 24/12/7

测试 gpio/I2C 通信  
安装 RPi.GPIO  
安装 Docker(拉取镜像失败)

---

### 24/12/8

3D 打印外壳建模  
团队成员开会
